#####
name: Unit
bidirect: False #Unidirectional or bidirectional
regist: True
noise_level: 1  #  noise level
port: 6019   #  port parameters
save_root: './output/Unit/NC+R/'
image_save: './output/Unit/NC+R/img/'


# lamda weight
Adv_lamda: 1
Cyc_lamda: 10
Corr_lamda: 20
Smooth_lamda: 10
Recon_kl_lamda: 0.01



epoch: 0        # starting epoch
n_epochs: 80       # How often do you want to display output images during training
batchSize: 1               # size of the batches
dataroot:  '/data1/T1T2/train2D/'      # root directory of the dataset
val_dataroot:  '/data1/T1T2/val2D/'
lr: 0.0001                   # initial learning rate
decay_epoch: 20            # epoch to start linearly decaying the learning rate to 0
size: 256                # size of the data crop
input_nc: 1         
output_nc: 1                  
cuda: True                
n_cpu: 1

# Unit
gen:
  dim: 64                     # number of filters in the bottommost layer
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  n_downsample: 2             # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                   # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 4                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan]
  num_scales: 3               # number of scales
  pad_type: reflect           # padding type [zero/reflect]

input_dim_a: 1                              # number of image channels [1/3]
input_dim_b: 1                              # number of image channels [1/3]